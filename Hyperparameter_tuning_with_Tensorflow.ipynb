{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PopeCollins/Hyperarameter-Tuning-with-Tensorflow-using-MNIST-Data/blob/main/Hyperparameter_tuning_with_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fR8hMnGHUL7",
        "outputId": "acb2ade0-e0fb-4def-994c-348a0f7163a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Load MNIST Data Set\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ZXB96l1cCTa-",
        "outputId": "157b9889-2508-42f7-99aa-938b18b69e91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b7168f2e350>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualise the second output\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lm0f-gAZDg7w"
      },
      "outputs": [],
      "source": [
        "# Create adam optimizer\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt_1 = Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kOQJLA9FVnz",
        "outputId": "ef9e4c8e-306a-446a-b839-5f7d5ced786a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.7142 - val_accuracy: 0.9149 - val_loss: 0.3098\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.3101 - val_accuracy: 0.9200 - val_loss: 0.2825\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.2844 - val_accuracy: 0.9256 - val_loss: 0.2730\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2738 - val_accuracy: 0.9259 - val_loss: 0.2680\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2687 - val_accuracy: 0.9265 - val_loss: 0.2672\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2676 - val_accuracy: 0.9246 - val_loss: 0.2704\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2618 - val_accuracy: 0.9258 - val_loss: 0.2650\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.2537 - val_accuracy: 0.9271 - val_loss: 0.2625\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2568 - val_accuracy: 0.9253 - val_loss: 0.2686\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.2502 - val_accuracy: 0.9280 - val_loss: 0.2638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7168ef45b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Base Model (Model 1)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model_1 = Sequential([layers.Input((28,28)),\n",
        "                      layers.Lambda (lambda x:x/255),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(10, activation =\"softmax\")])\n",
        "\n",
        "model_1.compile(optimizer =opt_1, loss=\"sparse_categorical_crossentropy\", metrics= [\"accuracy\"])\n",
        "model_1.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs= 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRTfYWYSJHXz",
        "outputId": "255f41df-a12e-492c-996a-ec475e300dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.5803 - val_accuracy: 0.9425 - val_loss: 0.2029\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.1966 - val_accuracy: 0.9494 - val_loss: 0.1698\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1521 - val_accuracy: 0.9578 - val_loss: 0.1420\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1319 - val_accuracy: 0.9590 - val_loss: 0.1357\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1161 - val_accuracy: 0.9591 - val_loss: 0.1363\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0997 - val_accuracy: 0.9635 - val_loss: 0.1222\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0890 - val_accuracy: 0.9671 - val_loss: 0.1125\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0780 - val_accuracy: 0.9676 - val_loss: 0.1123\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0754 - val_accuracy: 0.9680 - val_loss: 0.1110\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0685 - val_accuracy: 0.9647 - val_loss: 0.1211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7168fd29b0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from re import S\n",
        "# Adding number of parameter (Model 2)\n",
        "\n",
        "opt_2 = Adam(learning_rate = 0.001)\n",
        "\n",
        "model_2 = Sequential([layers.Input((28,28)),\n",
        "                      layers.Lambda (lambda x: x/255),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(32, activation =\"relu\"),\n",
        "                      layers.Dense(10, activation =\"softmax\")])\n",
        "\n",
        "model_2.compile(optimizer =opt_2, loss=\"sparse_categorical_crossentropy\", metrics= [\"accuracy\"])\n",
        "model_2.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs= 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HOqd62KLv-9",
        "outputId": "23f0b865-4c1c-4306-adb4-6c66cf2dbe26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3265 - loss: 1.8382 - val_accuracy: 0.3362 - val_loss: 1.7470\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3252 - loss: 1.8344 - val_accuracy: 0.3264 - val_loss: 1.7512\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3189 - loss: 1.8312 - val_accuracy: 0.3164 - val_loss: 1.8183\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3225 - loss: 1.8053 - val_accuracy: 0.3279 - val_loss: 1.8150\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3147 - loss: 1.8224 - val_accuracy: 0.3072 - val_loss: 2.0920\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3055 - loss: 1.8398 - val_accuracy: 0.2784 - val_loss: 2.0324\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2993 - loss: 1.8631 - val_accuracy: 0.3271 - val_loss: 1.9135\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3104 - loss: 1.8376 - val_accuracy: 0.3321 - val_loss: 1.8857\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3048 - loss: 1.8223 - val_accuracy: 0.2877 - val_loss: 1.9143\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3164 - loss: 1.7880 - val_accuracy: 0.2871 - val_loss: 1.9428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7168ef0340>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# increasing the learning rate\n",
        "\n",
        "opt_3 = Adam(learning_rate = 0.1)\n",
        "\n",
        "model_3 = Sequential([layers.Input((28,28)),\n",
        "                      layers.Lambda (lambda x: x/255),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(32, activation =\"relu\"),\n",
        "                      layers.Dense(10, activation =\"softmax\")])\n",
        "\n",
        "model_3.compile(optimizer =opt_3, loss=\"sparse_categorical_crossentropy\", metrics= [\"accuracy\"])\n",
        "model_3.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs= 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r85OFKxIOQAN",
        "outputId": "b68f3470-cdff-48af-e5bb-09107bd0cc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.4037 - val_accuracy: 0.9521 - val_loss: 0.1497\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.1041 - val_accuracy: 0.9686 - val_loss: 0.1000\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0685 - val_accuracy: 0.9754 - val_loss: 0.0798\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0558 - val_accuracy: 0.9766 - val_loss: 0.0770\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0396 - val_accuracy: 0.9713 - val_loss: 0.1013\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0365 - val_accuracy: 0.9765 - val_loss: 0.0821\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0273 - val_accuracy: 0.9764 - val_loss: 0.0875\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0267 - val_accuracy: 0.9742 - val_loss: 0.0991\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9780 - val_loss: 0.0963\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0179 - val_accuracy: 0.9783 - val_loss: 0.0878\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b71604dbee0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Greatly add number of parameter (Model 4)\n",
        "\n",
        "opt_4 = Adam(learning_rate = 0.001)\n",
        "\n",
        "model_4 = Sequential([layers.Input((28,28)),\n",
        "                      layers.Lambda (lambda x: x/255),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(128, activation =\"relu\"),\n",
        "                      layers.Dense(128, activation =\"relu\"),\n",
        "                      layers.Dense(128, activation =\"relu\"),\n",
        "                      layers.Dense(10, activation =\"softmax\")])\n",
        "\n",
        "model_4.compile(optimizer =opt_4, loss=\"sparse_categorical_crossentropy\", metrics= [\"accuracy\"])\n",
        "model_4.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs= 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uLKGLmu9Pdac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91006ecc-394a-40dd-923b-192e16409979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.7536 - val_accuracy: 0.9627 - val_loss: 0.3143\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9547 - loss: 0.3222 - val_accuracy: 0.9661 - val_loss: 0.2585\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.2628 - val_accuracy: 0.9678 - val_loss: 0.2356\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.2420 - val_accuracy: 0.9667 - val_loss: 0.2295\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.2319 - val_accuracy: 0.9665 - val_loss: 0.2254\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.2219 - val_accuracy: 0.9707 - val_loss: 0.2128\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.2195 - val_accuracy: 0.9689 - val_loss: 0.2067\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.2093 - val_accuracy: 0.9634 - val_loss: 0.2255\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.2125 - val_accuracy: 0.9726 - val_loss: 0.1942\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.2022 - val_accuracy: 0.9707 - val_loss: 0.2014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b71604c6ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Add regularization / Dropout to reduce overfitting\n",
        "\n",
        "from tensorflow.keras.regularizers import L2\n",
        "\n",
        "opt_5 = Adam(learning_rate = 0.001)\n",
        "\n",
        "model_5 = Sequential([layers.Input((28,28)),\n",
        "                      layers.Lambda (lambda x: x/255),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(128, activation =\"relu\", kernel_regularizer =L2(0.001)),\n",
        "                      layers.Dropout(0.05),\n",
        "                      layers.Dense(128, activation =\"relu\", kernel_regularizer =L2(0.001)),\n",
        "                      layers.Dropout(0.05),\n",
        "                      layers.Dense(128, activation =\"relu\", kernel_regularizer =L2(0.001)),\n",
        "                      layers.Dropout(0.05),\n",
        "                      layers.Dense(10, activation =\"softmax\")])\n",
        "\n",
        "model_5.compile(optimizer =opt_5, loss=\"sparse_categorical_crossentropy\", metrics= [\"accuracy\"])\n",
        "model_5.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs= 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Increasing the number of Epochs\n",
        "\n",
        "model_5.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs= 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJgGiym7rrfj",
        "outputId": "4373954b-e35a-4ee5-efad-eed6e7b35cdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.1912 - val_accuracy: 0.9698 - val_loss: 0.1935\n",
            "Epoch 2/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.1859 - val_accuracy: 0.9715 - val_loss: 0.1912\n",
            "Epoch 3/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.1922 - val_accuracy: 0.9704 - val_loss: 0.1937\n",
            "Epoch 4/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.1924 - val_accuracy: 0.9733 - val_loss: 0.1810\n",
            "Epoch 5/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.1899 - val_accuracy: 0.9720 - val_loss: 0.1860\n",
            "Epoch 6/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.1863 - val_accuracy: 0.9720 - val_loss: 0.1914\n",
            "Epoch 7/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.1844 - val_accuracy: 0.9717 - val_loss: 0.1880\n",
            "Epoch 8/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.1850 - val_accuracy: 0.9715 - val_loss: 0.1810\n",
            "Epoch 9/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.1826 - val_accuracy: 0.9720 - val_loss: 0.1872\n",
            "Epoch 10/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9714 - loss: 0.1858 - val_accuracy: 0.9745 - val_loss: 0.1815\n",
            "Epoch 11/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.1864 - val_accuracy: 0.9718 - val_loss: 0.1860\n",
            "Epoch 12/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.1881 - val_accuracy: 0.9722 - val_loss: 0.1805\n",
            "Epoch 13/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.1839 - val_accuracy: 0.9762 - val_loss: 0.1734\n",
            "Epoch 14/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.1819 - val_accuracy: 0.9721 - val_loss: 0.1847\n",
            "Epoch 15/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.1823 - val_accuracy: 0.9737 - val_loss: 0.1859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b71528578e0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3ix5nYGsfMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN+2dWijxMvvg9fhl2XtMnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}